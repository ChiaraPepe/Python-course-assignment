{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d2cd2b8",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "#### This script was written to perform an experimental test on a robot (Ambrogio ü§ñ‚ù§Ô∏è) we built for the Cajal Advanced Neuroscience Training Porgramme. A face recognition function that plays through a web-streaming camera gives the input to Ambrogio to turn his back and run away whenever he meets human faces! The first part of the task (camera stream and face recognition) is written in python. Then, a serial port comunication is established, where an Arduino runs a .ino file to complete the second part of the task (moving the wheels to run away:). The audio connection through the ears of the robot is also initialized in this script, but it doesn't generate any output for the current task.\n",
    "\n",
    "##### The script was modified and implemented from several scripts in the following github repositories and open web resources:  \n",
    "https://github.com/NoBlackBoxes/LastBlackBox/tree/master/course , https://github.com/NoBlackBoxes/LastBlackBox/tree/master/course/bootcamp/day_5/resources ,\n",
    "https://picamera.readthedocs.io/en/release-1.13/recipes2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d05ea",
   "metadata": {},
   "source": [
    "!/usr/bin/python3 #Written in python3\n",
    "\n",
    "- Run this script, then point a web browser at \"http://<this-IP-address>:8000/index.html\" (for example  http://192.168.137.183:8000/index.html) \n",
    "\n",
    "- Note: needs simplejpeg to be installed (pip3 install simplejpeg).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e69c3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! I'm editing the standard library!\n",
      "Requirement already satisfied: simplejpeg in c:\\users\\cpepe\\miniconda3\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\cpepe\\miniconda3\\lib\\site-packages (from simplejpeg) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install simplejpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1241e84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhttp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m server\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Condition\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msocket\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "#Import needed libraries\n",
    "\n",
    "## FOR LIVE STREAM\n",
    "import io\n",
    "import logging\n",
    "import socketserver\n",
    "from http import server\n",
    "from threading import Condition\n",
    "\n",
    "## FOR IMAGE AND AUDIO PROCESSING\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import socket\n",
    "import struct\n",
    "import pyaudio\n",
    "\n",
    "import serial\n",
    "import time\n",
    "\n",
    "## FOR HARDWARE CAMERA\n",
    "from picamera2 import Picamera2   \n",
    "from picamera2.encoders import JpegEncoder\n",
    "from picamera2.outputs import FileOutput\n",
    "\n",
    "PAGE = \"\"\"\\\n",
    "<html>\n",
    "<head>\n",
    "<head>\n",
    "<head>\n",
    "<head>\n",
    "\n",
    "<title>picamera2 MJPEG streaming demo</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Picamera2 MJPEG Streaming Demo</h1>\n",
    "<img src=\"stream.mjpg\" width=\"640\" height=\"480\" />\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3295a5a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'serial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Configure serial port\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m ser \u001b[38;5;241m=\u001b[39m \u001b[43mserial\u001b[49m\u001b[38;5;241m.\u001b[39mSerial()\n\u001b[0;32m      4\u001b[0m ser\u001b[38;5;241m.\u001b[39mbaudrate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m19200\u001b[39m\n\u001b[0;32m      5\u001b[0m ser\u001b[38;5;241m.\u001b[39mport \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/dev/ttyUSB0\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'serial' is not defined"
     ]
    }
   ],
   "source": [
    "# Configure serial port.\n",
    "## I first create a 'ser' object\n",
    "### I then set the rate at which data are trasmitted over the serial connection (baudrate) based on my device (Arduino and RasperryPi)\n",
    "#### I lastly set the port of the object 'ser' to the physical serial port that connect the Arduino and the RaspPi\n",
    "\n",
    "ser = serial.Serial()\n",
    "ser.baudrate = 19200\n",
    "ser.port = '/dev/ttyUSB0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce40804",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Open serial port\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mser\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[0;32m      4\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2.00\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ser' is not defined"
     ]
    }
   ],
   "source": [
    "# Open serial port to send/receive data\n",
    "\n",
    "ser.open()\n",
    "time.sleep(2.00) # Wait for connection before sending any data, for the sake of synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c874f8b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyaudio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Setup the audio connection\u001b[39;00m\n\u001b[0;32m      3\u001b[0m CHUNK_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m           \u001b[38;5;66;03m# Buffer size\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m FORMAT \u001b[38;5;241m=\u001b[39m \u001b[43mpyaudio\u001b[49m\u001b[38;5;241m.\u001b[39mpaInt16    \u001b[38;5;66;03m# Data type\u001b[39;00m\n\u001b[0;32m      5\u001b[0m CHANNELS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m                \u001b[38;5;66;03m# Number of channels\u001b[39;00m\n\u001b[0;32m      6\u001b[0m RATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m22050\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pyaudio' is not defined"
     ]
    }
   ],
   "source": [
    "# Audio connection\n",
    "## Not useful for the current task, but still Ambrogio has good ears that we need to initialize for further task:)\n",
    "\n",
    "##Setting up the audio parameter for audio processing using the PyAudio library \n",
    "\n",
    "CHUNK_SIZE = 4096           # Buffer size in bytes (n of audio frame processed at time)\n",
    "FORMAT = pyaudio.paInt16    # Data type\n",
    "CHANNELS = 2                # Number of channels, L and R ear\n",
    "RATE = 22050                # Sample rate (Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c1b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyAudio\n",
    "## Creating the 'audio' object as the interface to my robot's audio hardware\n",
    "audio = pyaudio.PyAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aefccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the audio stream, in order to then use the 'stream' object to read or perform real-time audio processing\n",
    "stream = audio.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEB STREAMING CAMERA\n",
    "##The classes defined are inherited from IO (used for streaming video over HTTP) and server.BaseHTTPRequestHandler (used to handle HTTP requests)\n",
    "\n",
    "class StreamingOutput(io.BufferedIOBase):\n",
    "    def __init__(self):\n",
    "        self.frame = None #initializing the attribute 'frame' used to store the latest video frame as a bytes-like object\n",
    "        self.condition = Condition() #initializing 'condition' for synchronization -> wait for a condition before proceeding\n",
    "\n",
    "    def write(self, buf):\n",
    "        with self.condition:\n",
    "            self.frame = buf\n",
    "            self.condition.notify_all()\n",
    "\n",
    "class StreamingHandler(server.BaseHTTPRequestHandler):\n",
    "    def do_GET(self):  #for GET requests \n",
    "        if self.path == '/':\n",
    "            self.send_response(301)\n",
    "            self.send_header('Location', '/index.html')\n",
    "            self.end_headers()\n",
    "        elif self.path == '/index.html':\n",
    "            content = PAGE.encode('utf-8')\n",
    "            self.send_response(200)\n",
    "            self.send_header('Content-Type', 'text/html')\n",
    "            self.send_header('Content-Length', len(content))\n",
    "            self.end_headers()\n",
    "            self.wfile.write(content)\n",
    "        elif self.path == '/stream.mjpg': \n",
    "            self.send_response(200)\n",
    "            self.send_header('Age', 0)\n",
    "            self.send_header('Cache-Control', 'no-cache, private')\n",
    "            self.send_header('Pragma', 'no-cache')\n",
    "            self.send_header('Content-Type', 'multipart/x-mixed-replace; boundary=FRAME')\n",
    "            self.end_headers()\n",
    "            \n",
    "            #Put the code in a \"try\" block to make it run indefinitely, continously serving video frames\n",
    "            try:\n",
    "                while True:\n",
    "                    with output.condition:\n",
    "                        output.condition.wait() #it waits for a condition to be notified indicating that a new frame is ready\n",
    "                        frame = output.frame #it retrieves the latest frame \n",
    "\n",
    "                        # Open the cv2 library to decode the image from a binary buffer\n",
    "                        ## The image is encoded in bytes, needs to be converted to a numpy array\n",
    "                        ### Color mode of the image is also specified\n",
    "                        #### 'Frame' variable results in the decoded image \n",
    "                        \n",
    "                        frame = cv2.imdecode(np.frombuffer(frame, dtype=np.uint8),\n",
    "                                             cv2.IMREAD_COLOR) \n",
    "                        \n",
    "                        \n",
    "                       \n",
    "                        # HERE CAN GO ALL IMAGE PROCESSING\n",
    "                \n",
    "                        frame = frame[::-1].copy() #flip image horizontally + create a copy of the modified frame\n",
    "                        det = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\") #load a Haar Cascade classifier for frontal face detection (pre-trained model)\n",
    "\n",
    "                        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #convert the frame to greyscale, the face-det algorithm works on greyscale\n",
    "\n",
    "                        #detect face and adjust parameters for face detection sensitivy and accuracy\n",
    "                        rects = det.detectMultiScale(gray, \n",
    "                                                     scaleFactor=1.1, \n",
    "                                                     minNeighbors=5, \n",
    "                                                     minSize=(30, 30), \n",
    "                                                     flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "                        for (x, y, w, h) in rects:\n",
    "                            # draw a rectangle around the detected face where:\n",
    "                            ## x: x location\n",
    "                            ## y: y location\n",
    "                            ## w: width of the rectangle \n",
    "                            ## h: height of the rectangle\n",
    "                            ## Remember, order in images: [y, x, channel]\n",
    "                            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 20)\n",
    "                            \n",
    "                            # Face detected. Send command to robot to run!\n",
    "                            #In order to make the robot run we are sending data to the serial port to talk with the Arduino, which will run the following .ino script to make the wheels move \"https://github.com/NoBlackBoxes/LastBlackBox/blob/master/course/bootcamp/day_2/resources/arduino/servo_test/servo_test.ino\"\n",
    "                            ser.write(b'b')\n",
    "                            \n",
    "        \n",
    "\n",
    "                        cv2.imwrite(\"test_face.jpg\", frame) #save the frame with rectangle around the detected face\n",
    "                            \n",
    "                        # and now convert it back to JPEG to stream it\n",
    "                    _, frame = cv2.imencode('.JPEG', frame)\n",
    "\n",
    "                    self.wfile.write(b'--FRAME\\r\\n')\n",
    "                    self.send_header('Content-Type', 'image/jpeg')\n",
    "                    self.send_header('Content-Length', len(frame))\n",
    "                    self.end_headers()\n",
    "                    self.wfile.write(frame)\n",
    "                    self.wfile.write(b'\\r\\n')\n",
    "                    \n",
    "                    #AUDIO RECORDING, NOT USED FOR THE CURRENT TASK\n",
    "                    \n",
    "                    # Read audio data from the stream\n",
    "                    raw_data = stream.read(CHUNK_SIZE)\n",
    "\n",
    "                    # Convert raw_data to left and right channel\n",
    "                    interleaved_data = np.frombuffer(raw_data, dtype=np.int16)\n",
    "                    left = interleaved_data[::2]\n",
    "                    right = interleaved_data[1::2]\n",
    "\n",
    "                    # Report volume (on left)\n",
    "                    print(\"L: {0:.2f}, R: {1:.2f}\".format(np.mean(np.abs(left)), np.mean(np.abs(right))))\n",
    "                    value = float(np.mean(np.abs(left)))\n",
    "                    \n",
    "                        \n",
    "                    \n",
    "            except Exception as e:\n",
    "                logging.warning(\n",
    "                    'Removed streaming client %s: %s',\n",
    "                    self.client_address, str(e))\n",
    "        else:\n",
    "            self.send_error(404)\n",
    "            self.end_headers()\n",
    "\n",
    "\n",
    "class StreamingServer(socketserver.ThreadingMixIn, server.HTTPServer):\n",
    "    allow_reuse_address = True\n",
    "    daemon_threads = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f291d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingServer(socketserver.ThreadingMixIn, server.HTTPServer):\n",
    "    allow_reuse_address = True\n",
    "    daemon_threads = True\n",
    "\n",
    "# Open the camera and stream a low res image\n",
    "picam2 = Picamera2()\n",
    "picam2.configure(picam2.create_video_configuration(main={\"size\": (640, 480)}))\n",
    "output = StreamingOutput()\n",
    "picam2.start_recording(JpegEncoder(), FileOutput(output))\n",
    "\n",
    "try:\n",
    "    address = ('', 8000)\n",
    "    server = StreamingServer(address, StreamingHandler)\n",
    "    server.serve_forever()\n",
    "finally:\n",
    "    picam2.stop_recording()\n",
    "    ser.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course-env",
   "language": "python",
   "name": "course-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
