{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d2cd2b8",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "LP: try to keep your markdown text clean! Use `#` only for titles, and keep the text to default\n",
    "\n",
    "This script was written to perform an experimental test on a robot (Ambrogio ü§ñ‚ù§Ô∏è) we built for the Cajal Advanced Neuroscience Training Porgramme. A face recognition function that plays through a web-streaming camera gives the input to Ambrogio to turn his back and run away whenever he meets human faces! The first part of the task (camera stream and face recognition) is written in python. Then, a serial port comunication is established, where an Arduino runs a .ino file to complete the second part of the task (moving the wheels to run away:). The audio connection through the ears of the robot is also initialized in this script, but it doesn't generate any output for the current task.\n",
    "\n",
    "### Sources \n",
    "The script was modified and implemented from several scripts in the following github repositories and open web resources:  \n",
    "https://github.com/NoBlackBoxes/LastBlackBox/tree/master/course , https://github.com/NoBlackBoxes/LastBlackBox/tree/master/course/bootcamp/day_5/resources ,\n",
    "https://picamera.readthedocs.io/en/release-1.13/recipes2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d05ea",
   "metadata": {},
   "source": [
    "!/usr/bin/python3 #Written in python3\n",
    "\n",
    "- Run this script, then point a web browser at \"http://this-IP-address:8000/index.html\" (for example  http://192.168.137.183:8000/index.html) \n",
    "\n",
    "- Note: needs simplejpeg to be installed (pip3 install simplejpeg).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LP: happy to see that your Python standard library is still messed up by the course! :)\n",
    "# I'd recommend removing the \"Hey! I'm editing the standard library!\" quote from your random library!!\n",
    "pip install simplejpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1241e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed libraries\n",
    "\n",
    "## FOR LIVE STREAM\n",
    "import io\n",
    "import logging\n",
    "import socketserver\n",
    "from http import server\n",
    "from threading import Condition\n",
    "\n",
    "## FOR IMAGE AND AUDIO PROCESSING\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import socket\n",
    "import struct\n",
    "import pyaudio\n",
    "\n",
    "import serial\n",
    "import time\n",
    "\n",
    "## FOR HARDWARE CAMERA\n",
    "from picamera2 import Picamera2   \n",
    "from picamera2.encoders import JpegEncoder\n",
    "from picamera2.outputs import FileOutput\n",
    "\n",
    "PAGE = \"\"\"\\\n",
    "<html>\n",
    "<head>\n",
    "<head>\n",
    "<head>\n",
    "<head>\n",
    "\n",
    "<title>picamera2 MJPEG streaming demo</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Picamera2 MJPEG Streaming Demo</h1>\n",
    "<img src=\"stream.mjpg\" width=\"640\" height=\"480\" />\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3295a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LP: single # in comments!\n",
    "# Configure serial port.\n",
    "# I first create a 'ser' object\n",
    "# I then set the rate at which data are trasmitted over the serial connection (baudrate) based on my device (Arduino and RasperryPi)\n",
    "# I lastly set the port of the object 'ser' to the physical serial port that connect the Arduino and the RaspPi\n",
    "\n",
    "ser = serial.Serial()\n",
    "ser.baudrate = 19200\n",
    "ser.port = '/dev/ttyUSB0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce40804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open serial port to send/receive data\n",
    "\n",
    "ser.open()\n",
    "time.sleep(2.00) # Wait for connection before sending any data, for the sake of synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio connection\n",
    "# Not useful for the current task, but still Ambrogio has good ears that we need to initialize for further task:)\n",
    "\n",
    "# Setting up the audio parameter for audio processing using the PyAudio library \n",
    "\n",
    "CHUNK_SIZE = 4096           # Buffer size in bytes (n of audio frame processed at time)\n",
    "FORMAT = pyaudio.paInt16    # Data type\n",
    "CHANNELS = 2                # Number of channels, L and R ear\n",
    "RATE = 22050                # Sample rate (Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c1b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyAudio\n",
    "## Creating the 'audio' object as the interface to my robot's audio hardware\n",
    "audio = pyaudio.PyAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aefccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the audio stream, in order to then use the 'stream' object to read or perform real-time audio processing\n",
    "stream = audio.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEB STREAMING CAMERA\n",
    "##The classes defined are inherited from IO (used for streaming video over HTTP) and server.BaseHTTPRequestHandler (used to handle HTTP requests)\n",
    "\n",
    "class StreamingOutput(io.BufferedIOBase):\n",
    "    def __init__(self):\n",
    "        self.frame = None #initializing the attribute 'frame' used to store the latest video frame as a bytes-like object\n",
    "        self.condition = Condition() #initializing 'condition' for synchronization -> wait for a condition before proceeding\n",
    "\n",
    "    def write(self, buf):\n",
    "        with self.condition:\n",
    "            self.frame = buf\n",
    "            self.condition.notify_all()\n",
    "\n",
    "class StreamingHandler(server.BaseHTTPRequestHandler):\n",
    "    # LP: Not sure you wrote this code, but this is not something I would recommend following!\n",
    "    # the loop for serving frames could have been factored in a separate function, \n",
    "    # and the resonses and headers to send in a dictionary based on the path :)\n",
    "    def do_GET(self):  #for GET requests \n",
    "        if self.path == '/':\n",
    "            self.send_response(301)\n",
    "            self.send_header('Location', '/index.html')\n",
    "            self.end_headers()\n",
    "        elif self.path == '/index.html':\n",
    "            content = PAGE.encode('utf-8')\n",
    "            self.send_response(200)\n",
    "            self.send_header('Content-Type', 'text/html')\n",
    "            self.send_header('Content-Length', len(content))\n",
    "            self.end_headers()\n",
    "            self.wfile.write(content)\n",
    "        elif self.path == '/stream.mjpg': \n",
    "            self.send_response(200)\n",
    "            self.send_header('Age', 0)\n",
    "            self.send_header('Cache-Control', 'no-cache, private')\n",
    "            self.send_header('Pragma', 'no-cache')\n",
    "            self.send_header('Content-Type', 'multipart/x-mixed-replace; boundary=FRAME')\n",
    "            self.end_headers()\n",
    "            \n",
    "            #Put the code in a \"try\" block to make it run indefinitely, continously serving video frames\n",
    "            try:\n",
    "                while True:\n",
    "                    with output.condition:\n",
    "                        output.condition.wait() #it waits for a condition to be notified indicating that a new frame is ready\n",
    "                        frame = output.frame #it retrieves the latest frame \n",
    "\n",
    "                        # Open the cv2 library to decode the image from a binary buffer\n",
    "                        ## The image is encoded in bytes, needs to be converted to a numpy array\n",
    "                        ### Color mode of the image is also specified\n",
    "                        #### 'Frame' variable results in the decoded image \n",
    "                        \n",
    "                        frame = cv2.imdecode(np.frombuffer(frame, dtype=np.uint8),\n",
    "                                             cv2.IMREAD_COLOR) \n",
    "                        \n",
    "                        \n",
    "                       \n",
    "                        # HERE CAN GO ALL IMAGE PROCESSING\n",
    "                        # LP: how f*#@ing awsome is that in Python? :)\n",
    "                        frame = frame[::-1].copy() #flip image horizontally + create a copy of the modified frame\n",
    "                        det = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\") #load a Haar Cascade classifier for frontal face detection (pre-trained model)\n",
    "\n",
    "                        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #convert the frame to greyscale, the face-det algorithm works on greyscale\n",
    "\n",
    "                        #detect face and adjust parameters for face detection sensitivy and accuracy\n",
    "                        rects = det.detectMultiScale(gray, \n",
    "                                                     scaleFactor=1.1, \n",
    "                                                     minNeighbors=5, \n",
    "                                                     minSize=(30, 30), \n",
    "                                                     flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "                        for (x, y, w, h) in rects:\n",
    "                            # draw a rectangle around the detected face where:\n",
    "                            ## x: x location\n",
    "                            ## y: y location\n",
    "                            ## w: width of the rectangle \n",
    "                            ## h: height of the rectangle\n",
    "                            ## Remember, order in images: [y, x, channel]\n",
    "                            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 20)\n",
    "                            \n",
    "                            # Face detected. Send command to robot to run!\n",
    "                            #In order to make the robot run we are sending data to the serial port to talk with the Arduino, which will run the following .ino script to make the wheels move \"https://github.com/NoBlackBoxes/LastBlackBox/blob/master/course/bootcamp/day_2/resources/arduino/servo_test/servo_test.ino\"\n",
    "                            ser.write(b'b')\n",
    "                            \n",
    "        \n",
    "\n",
    "                        cv2.imwrite(\"test_face.jpg\", frame) #save the frame with rectangle around the detected face\n",
    "                            \n",
    "                        # and now convert it back to JPEG to stream it\n",
    "                    _, frame = cv2.imencode('.JPEG', frame)\n",
    "\n",
    "                    self.wfile.write(b'--FRAME\\r\\n')\n",
    "                    self.send_header('Content-Type', 'image/jpeg')\n",
    "                    self.send_header('Content-Length', len(frame))\n",
    "                    self.end_headers()\n",
    "                    self.wfile.write(frame)\n",
    "                    self.wfile.write(b'\\r\\n')\n",
    "                    \n",
    "                    #AUDIO RECORDING, NOT USED FOR THE CURRENT TASK\n",
    "                    \n",
    "                    # Read audio data from the stream\n",
    "                    raw_data = stream.read(CHUNK_SIZE)\n",
    "\n",
    "                    # Convert raw_data to left and right channel\n",
    "                    interleaved_data = np.frombuffer(raw_data, dtype=np.int16)\n",
    "                    left = interleaved_data[::2]\n",
    "                    right = interleaved_data[1::2]\n",
    "\n",
    "                    # Report volume (on left)\n",
    "                    print(\"L: {0:.2f}, R: {1:.2f}\".format(np.mean(np.abs(left)), np.mean(np.abs(right))))\n",
    "                    value = float(np.mean(np.abs(left)))\n",
    "                    \n",
    "                        \n",
    "                    \n",
    "            except Exception as e:\n",
    "                logging.warning(\n",
    "                    'Removed streaming client %s: %s',\n",
    "                    self.client_address, str(e))\n",
    "        else:\n",
    "            self.send_error(404)\n",
    "            self.end_headers()\n",
    "\n",
    "# LP: sweet, there's even multiple inheritance here! :D \n",
    "class StreamingServer(socketserver.ThreadingMixIn, server.HTTPServer):\n",
    "    allow_reuse_address = True\n",
    "    daemon_threads = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f291d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LP: duplicated, could have been polished:\n",
    "class StreamingServer(socketserver.ThreadingMixIn, server.HTTPServer):\n",
    "    allow_reuse_address = True\n",
    "    daemon_threads = True\n",
    "\n",
    "# Open the camera and stream a low res image\n",
    "picam2 = Picamera2()\n",
    "picam2.configure(picam2.create_video_configuration(main={\"size\": (640, 480)}))\n",
    "output = StreamingOutput()\n",
    "picam2.start_recording(JpegEncoder(), FileOutput(output))\n",
    "\n",
    "try:\n",
    "    address = ('', 8000)\n",
    "    server = StreamingServer(address, StreamingHandler)\n",
    "    server.serve_forever()\n",
    "finally:\n",
    "    picam2.stop_recording()\n",
    "    ser.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:course_env]",
   "language": "python",
   "name": "conda-env-course_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
